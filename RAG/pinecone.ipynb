{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPKw6LBDMWvqkTovtmhWRne"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!pip install pinecone"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kTlS3JTcdTVj","executionInfo":{"status":"ok","timestamp":1743311442219,"user_tz":-330,"elapsed":3447,"user":{"displayName":"Mohul YP","userId":"12458545381722168229"}},"outputId":"b5748850-5b41-4bd7-b8b1-2a4a8580fa0d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pinecone\n","  Downloading pinecone-6.0.2-py3-none-any.whl.metadata (9.0 kB)\n","Requirement already satisfied: certifi>=2019.11.17 in /usr/local/lib/python3.11/dist-packages (from pinecone) (2025.1.31)\n","Collecting pinecone-plugin-interface<0.0.8,>=0.0.7 (from pinecone)\n","  Downloading pinecone_plugin_interface-0.0.7-py3-none-any.whl.metadata (1.2 kB)\n","Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from pinecone) (2.8.2)\n","Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.11/dist-packages (from pinecone) (4.12.2)\n","Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from pinecone) (2.3.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.5.3->pinecone) (1.17.0)\n","Downloading pinecone-6.0.2-py3-none-any.whl (421 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m421.9/421.9 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pinecone_plugin_interface-0.0.7-py3-none-any.whl (6.2 kB)\n","Installing collected packages: pinecone-plugin-interface, pinecone\n","Successfully installed pinecone-6.0.2 pinecone-plugin-interface-0.0.7\n"]}]},{"cell_type":"code","source":["import nltk\n","nltk.data.path.append(\"/usr/local/nltk_data\")\n","nltk.download(\"wordnet\", download_dir=\"/usr/local/nltk_data\")\n","nltk.download(\"omw-1.4\", download_dir=\"/usr/local/nltk_data\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Qo1XLdEZeORj","executionInfo":{"status":"ok","timestamp":1743311662034,"user_tz":-330,"elapsed":461,"user":{"displayName":"Mohul YP","userId":"12458545381722168229"}},"outputId":"8bffabd7-af3d-4a3c-f6e6-085b169f8449"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package wordnet to /usr/local/nltk_data...\n","[nltk_data] Downloading package omw-1.4 to /usr/local/nltk_data...\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WtL5l0aEb7yP","executionInfo":{"status":"ok","timestamp":1743313845858,"user_tz":-330,"elapsed":108712,"user":{"displayName":"Mohul YP","userId":"12458545381722168229"}},"outputId":"5d41cc21-b834-4eb6-95da-1a1c7d81731d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cpu\n","Enter agricultural website URL: https://www.gvsprinklers.com.au/blog/5-types-irrigation-systems/\n","Embedding shape: 384\n","Embedding shape: 384\n","Embedding shape: 384\n","Stored 3 chunks in Pinecone.\n","Embeddings stored successfully!\n"]}],"source":["import requests\n","import torch\n","from bs4 import BeautifulSoup\n","import re\n","import nltk\n","from nltk.corpus import stopwords\n","import spacy\n","from sentence_transformers import SentenceTransformer\n","from pinecone import Pinecone, ServerlessSpec\n","import os\n","\n","\n","# Download necessary NLTK resources\n","try:\n","    nltk.download('stopwords', quiet=True)\n","except Exception as e:\n","    print(f\"Warning: NLTK resource download issue. Error: {e}\")\n","\n","# Load spaCy model for NER and POS tagging\n","try:\n","    nlp = spacy.load(\"en_core_web_sm\")\n","except:\n","    print(\"Warning: spaCy model 'en_core_web_sm' not found. Using a simple pipeline.\")\n","    nlp = spacy.blank(\"en\")\n","\n","# Check for GPU availability\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","print(f\"Using device: {device}\")\n","\n","# Initialize Pinecone\n","pc = Pinecone(api_key=os.environ.get(\"PINECONE_API_KEY\", \"pcsk_5KEN7q_TRVH2gFB5Xgh6DjTx6VVfADn2rRow5z5KWYd3cFVguHNbfWJH2yndKDyMNfKpsP\"))\n","index_name = \"agribot\"\n","\n","index = pc.Index(index_name)\n","\n","\n","# Load a different embedding model (all-MiniLM-L6-v2)\n","model = SentenceTransformer('all-MiniLM-L6-v2')\n","\n","def scrape_text(url):\n","    \"\"\"Scrapes and extracts clean text from a webpage.\"\"\"\n","    response = requests.get(url)\n","    if response.status_code != 200:\n","        print(\"Failed to retrieve webpage.\")\n","        return None\n","\n","    soup = BeautifulSoup(response.text, \"html.parser\")\n","    paragraphs = soup.find_all(\"p\")\n","    text = \" \".join([para.get_text() for para in paragraphs])\n","    return re.sub(r'\\s+', ' ', text).strip()\n","\n","def preprocess_text(text):\n","    \"\"\"Performs NLP preprocessing: tokenization, stopword removal, lemmatization, NER, and POS tagging.\"\"\"\n","    stop_words = set(stopwords.words('english'))\n","\n","    # Remove punctuation, dates, years, numbers, and lowercase text\n","    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n","    text = re.sub(r'\\b\\d{1,2}[-/]\\d{1,2}[-/]\\d{2,4}\\b', '', text)  # Remove dates in various formats (e.g., 01/01/2022)\n","    text = re.sub(r'\\b\\d{4}\\b', '', text)  # Remove years (e.g., 2022)\n","    text = re.sub(r'\\b\\d+\\b', '', text)  # Remove any numbers\n","\n","    tokens = text.split()\n","    filtered_tokens = [token for token in tokens if token not in stop_words]\n","\n","    # Named entity recognition and POS tagging with spaCy\n","    doc = nlp(\" \".join(filtered_tokens))\n","    named_entities = [ent.text for ent in doc.ents]\n","\n","    # Count POS tags\n","    pos_counts = {}\n","    for token in doc:\n","        pos_tag = token.pos_\n","        pos_counts[pos_tag] = pos_counts.get(pos_tag, 0) + 1\n","\n","    # Lemmatization with spaCy\n","    lemmatized_tokens = [token.lemma_ for token in doc]\n","\n","    return \" \".join(lemmatized_tokens), named_entities, pos_counts\n","\n","def chunk_text(text, max_chunk_size=200):\n","    \"\"\"Splits long text into smaller chunks for better embedding performance.\"\"\"\n","    sentences = re.split(r'(?<=[.!?])\\s+', text)\n","    chunks, chunk = [], []\n","\n","    for sentence in sentences:\n","        chunk.append(sentence)\n","        if len(\" \".join(chunk).split()) > max_chunk_size:\n","            chunks.append(\" \".join(chunk))\n","            chunk = []\n","\n","    if chunk:\n","        chunks.append(\" \".join(chunk))\n","\n","    return chunks\n","\n","def store_embeddings(url):\n","    \"\"\"Processes text from a website, generates embeddings, and stores them in Pinecone.\"\"\"\n","    text = scrape_text(url)\n","    if not text:\n","        return\n","\n","    text_chunks = chunk_text(text)\n","    for i, chunk in enumerate(text_chunks):\n","        processed_text, named_entities, pos_counts = preprocess_text(chunk)\n","        embedding = model.encode(processed_text).tolist()\n","\n","        # Print to verify the embedding dimension is 768\n","        print(f\"Embedding shape: {len(embedding)}\")  # This should print 768\n","\n","        metadata = {\n","            \"url\": url,\n","            \"chunk_id\": i,\n","            \"named_entities\": named_entities,\n","            \"top_pos_tags\": list(pos_counts.keys())[:5]\n","        }\n","\n","        index.upsert(vectors=[{\"id\": f\"{url}_{i}\", \"values\": embedding, \"metadata\": metadata}])\n","\n","    print(f\"Stored {len(text_chunks)} chunks in Pinecone.\")\n","\n","if __name__ == \"__main__\":\n","    url = input(\"Enter agricultural website URL: \")\n","    store_embeddings(url)\n","    print(\"Embeddings stored successfully!\")\n"]},{"cell_type":"code","source":[],"metadata":{"id":"wLPMLJ95eF56"},"execution_count":null,"outputs":[]}]}